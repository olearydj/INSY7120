{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Regression - Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "This notebook introduces the Scikit-Learn interface for cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "Load the packages and configure environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "Using the Boston data from HW1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the data set directly from the web using pandas\n",
    "url = \"https://raw.githubusercontent.com/olearydj/INSY7120/refs/heads/main/notebooks/data/Boston.csv\"\n",
    "boston = pd.read_csv(url)\n",
    "# get the predictors of interest\n",
    "X = boston.loc[:,'zn':]\n",
    "y = boston[['crim']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Proper Dataset Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "First, hold out a test set for final assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train_val and y_train_val are for all model development (training and CV)\n",
    "# X_test and y_test are reserved for final assessment of the resulting model\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## `cross_val_score`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "Use for quick evaluations of test error with a single metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "# Simple cross-validation with default 5-fold\n",
    "scores = cross_val_score(model, X_train_val, y_train_val, cv=5, scoring='r2')\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## `cross_validate`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "For more thorough analysis. Returns a dict of scores and timing information for both test and train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "# use pretty print to make structures easier to read\n",
    "from pprint import pprint as pp\n",
    "\n",
    "# Multiple metrics and training scores\n",
    "results = cross_validate(model, X_train_val, y_train_val, cv=5, \n",
    "                        scoring=['r2', 'neg_root_mean_squared_error', 'neg_median_absolute_error'],\n",
    "                        return_train_score=True)\n",
    "pp(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "Note that the scores are the same. By default, these methods create folds based on the order of the data provided. For example, if there are 5 folds, the first 20% of the data is assigned to the first fold, the second 20% to the second, and so on. They inherit the random order of the `test_train_split` (and its seed). In SKL syntax, they default to `shuffle=False`).\n",
    "\n",
    "For greater control over this process, you can create a CV splitter with `shuffle=True` and fixed random state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, RepeatedKFold\n",
    "\n",
    "# For k-fold cross-validation on the training set\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# For repeated k-fold to get more stable estimates\n",
    "rkf = RepeatedKFold(n_splits=5, n_repeats=10, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "This code does not perform the split, it only initializes a splitter, which can then be used in `cross_val_score` or `cross_validate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass this CV splitter to cross_val_score\n",
    "scores = cross_val_score(model, X_train_val, y_train_val, cv=kf)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## Fit and Evaluate the Final Model on Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "Once we are happy with the scores we have to refit the model. The CV process doesn't keep the models built for each fold. And we ultimately want to fit with all the `train_val` data anyway, before finally evaluating the result on the held-out `test` set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After selecting the best model through cross-validation\n",
    "# Fit the final model on all training data\n",
    "final_model = LinearRegression()\n",
    "final_model.fit(X_train_val, y_train_val)\n",
    "\n",
    "# Evaluate on the held-out test set\n",
    "test_score = final_model.score(X_test, y_test)\n",
    "print(f\"Final model RÂ² on test set: {test_score:.4f}\")\n",
    "\n",
    "# You can also calculate other metrics on the test set\n",
    "from sklearn.metrics import mean_squared_error, median_absolute_error\n",
    "\n",
    "y_pred = final_model.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = median_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f\"Root Mean Squared Error on test set: {rmse:.4f}\")\n",
    "print(f\"Median Absolute Error on test set: {mae:.4f}\")\n",
    "\n",
    "# Optional: Examine the model coefficients\n",
    "coefficients = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Coefficient': final_model.coef_[0]\n",
    "}).sort_values('Coefficient', ascending=False)\n",
    "\n",
    "print(\"\\nModel Coefficients:\")\n",
    "print(coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
