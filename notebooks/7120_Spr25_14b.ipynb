{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "Continuing our discussion of DTs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "print(iris.feature_names)\n",
    "print(iris.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data\n",
    "y = iris.target\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training (n=105) and testing (n=45) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create and train a decision tree classifier\n",
    "tree_clf = DecisionTreeClassifier(max_depth=4)\n",
    "tree_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = tree_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "100% accuracy on the test data, even for a single split, is noteworthy.\n",
    "\n",
    "Let's see if we just got lucky. 5-fold CV will give us a better estimate of the model's performance on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Use 5-fold cross-validation\n",
    "cv_scores = cross_val_score(tree_clf, X, y, cv=5)\n",
    "\n",
    "print(f\"Cross-validation scores: {cv_scores}\")\n",
    "print(f\"Mean CV score: {cv_scores.mean():.2f}\")\n",
    "print(f\"Standard deviation: {cv_scores.std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plot_tree(tree_clf, filled=True, feature_names=iris.feature_names, \n",
    "          class_names=iris.target_names, rounded=True, fontsize=12)\n",
    "plt.title('Decision Tree')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print some information about the tree\n",
    "print(f\"Number of nodes: {tree_clf.tree_.node_count}\")\n",
    "print(f\"Tree depth: {tree_clf.get_depth()}\")\n",
    "print(f\"Number of leaves: {tree_clf.get_n_leaves()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "Each node contains:\n",
    "\n",
    "- Decision feature and threshold\n",
    "- Gini score for that node distribution\n",
    "- Number of samples in the node\n",
    "- Distribution of samples: setosa, versicolor, virginica\n",
    "- Majority class (tie goes to the class with the lowest index in the target array)\n",
    "\n",
    "Starting from the top:\n",
    "\n",
    "1. **Root Node**: The first decision is based on petal width ≤ 0.8 cm\n",
    "   - If TRUE (left branch): The flower is classified as \"setosa\" with 100% certainty (gini = 0.0)\n",
    "   - If FALSE (right branch): Continue to the next decision\n",
    "2. **Second Level** (right branch): Check if petal width ≤ 1.75 cm\n",
    "   - If TRUE (left branch): Likely versicolor, but needs more checks\n",
    "   - If FALSE (right branch): Continue checking for virginica\n",
    "3. **Third Level**: \n",
    "   - Left path checks petal length ≤ 4.95 cm, then further splits on petal width ≤ 1.6 cm\n",
    "   - Right path checks petal length ≤ 4.85 cm, then further splits on sepal width ≤ 3.1 cm\n",
    "\n",
    "The key insights:\n",
    "- Setosa is very easy to identify (just one rule: petal width ≤ 0.8 cm)\n",
    "- Versicolor and virginica require more complex rules to separate\n",
    "- As we get to the leaf nodes (bottom), most have gini = 0.0, meaning they're pure classifications\n",
    "- The model achieved 100% accuracy because it found perfect separation rules\n",
    "\n",
    "The tree demonstrates that even a relatively simple decision tree can perfectly classify the Iris dataset because the species are fairly well-separated in the feature space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## The SKL Way"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "Here we will demonstrate the general process for model selection and evaluation using SKL pipelines.\n",
    "\n",
    "First, load the packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "Then load the data and split it into test and train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "Create a `pipeline` object that defines the steps to apply in the train / fit methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline with preprocessing and model\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Standardize features\n",
    "    ('classifier', DecisionTreeClassifier(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "Assume we want to test results for a range of depths for the DT. We can define a dictionary of parameters and the range of interest. Note the syntax `classifier__max_depth` where the double-underbar separates the pipeline step name and the corresponding parameter of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid for grid search\n",
    "param_grid = {\n",
    "    'classifier__max_depth': np.arange(1, 10)  # Try depths 1-9\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "Use `GridSearchCV` to search the parameter grid using cross-validation. First we create the properly specified object instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    scoring='accuracy',\n",
    "    return_train_score=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "Calling the `fit` method performs the following:\n",
    "\n",
    "- For each parameter value specified in the grid\n",
    "- Create a 5-fold split\n",
    "- Scale the folds appropriately\n",
    "- Fit the classifier on 4 folds\n",
    "- Generate predictions for the 5th\n",
    "- Score the predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "The best resulting parameter and cv score is found in the `best_params_` and `best_score_` attributes of the resulting object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation score: {grid_search.best_score_:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "Pick the best model using `best_estimator_` (model fit with the best parameter) and sore it on the original test data to estimate its performance on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "best_model = grid_search.best_estimator_\n",
    "test_accuracy = best_model.score(X_test, y_test)\n",
    "print(f\"Test accuracy with best model: {test_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "Generate a classification report for the test data and predicitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More detailed evaluation\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=iris.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "Feature importances are calculated based on their contribution to decreasing impurity across all nodes in the tree. This information is a natural byproduct of the DT process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show feature importances\n",
    "importances = best_model.named_steps['classifier'].feature_importances_\n",
    "for feature, importance in zip(iris.feature_names, importances):\n",
    "    print(f\"{feature}: {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
