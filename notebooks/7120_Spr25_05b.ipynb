{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "The following cell sets up the Colab environment. No changes are made if run locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If running on Colab, set up the environment\n",
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    # !pip install requests wquantiles\n",
    "    !mkdir -p /content/data\n",
    "    %cd /content\n",
    "    !wget -q https://raw.githubusercontent.com/olearydj/INSY7120/refs/heads/main/notebooks/common.py -O common.py\n",
    "\n",
    "import common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Simple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "This example is from HOML, chapter 1:\n",
    "https://colab.research.google.com/github/ageron/handson-ml3/blob/main/01_the_machine_learning_landscape.ipynb\n",
    "\n",
    "Load life satisfaction data and look at the first few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and prepare the data\n",
    "data_root = \"https://github.com/ageron/data/raw/main/\"\n",
    "lifesat = pd.read_csv(data_root + \"lifesat/lifesat.csv\")\n",
    "lifesat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "The data is a table of life satisfaction rating for selected countries. Gross domestic product (GDP) is also given. Use `info` and `describe` dataframe methods to learn more about what we are working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lifesat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "lifesat.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "What is the relationship between GDP and life satisfaction?\n",
    "\n",
    "- GDP is a numerical predictor\n",
    "- Life satisfaction is a numerical outcome\n",
    "\n",
    "Predict quantitative response on the basis of a single predictor â†’ simple linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### Scikit-learn Process\n",
    "\n",
    "We'll use scikit-learn to perform this analysis. The general process is consistent across all model types:\n",
    "\n",
    "1. Prepare the data, e.g. split out predictors (`X`) and outcome (`y`).\n",
    "2. Initialize the selected model with desired parameters, e.g. `LinearRegression`\n",
    "3. Fit the model using training data, e.g. `model.fit(X, y)`\n",
    "4. Evaluate the model performance and tune / adjust until satisfied.\n",
    "5. Use the predict method of the resulting model to get predictions for new data, e.g. `model.predict(x_0)`.\n",
    "\n",
    "At most steps we will explore the results, adjust, and iterate as required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "### Prepare the Data\n",
    "\n",
    "We've already explored the data. No cleaning appears necessary, so let's extract `X` and `y` from `lifesat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = lifesat[[\"GDP per capita (USD)\"]].values\n",
    "y = lifesat[[\"Life satisfaction\"]].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "A few notes are in order.\n",
    "\n",
    "First, about the notation. Capital `X` and lowercase `y` are used by convention. Here, capitalization is intended to denote a matrix, not that it is a random variable. There will normally be more than a single predictor, so `X` is assumed to be size `n x p`, where `n` is the number of observations and `p` is the number of predictors. Similarly, `y` is expected to be a single output for each set of `n` observed values, `X`.\n",
    "\n",
    "In the particular example of Simple Linear Regression, `X` is a single column, but the capital notation is maintained by convention, signalling that it is the predictor.\n",
    "\n",
    "Second, note the double-bracket notation above, e.g. `lifestat[[\"GDP per capita (USD)\"]].values`. This is done to ensure that `X` and `y` remain 2-dimensional arrays (matricies) rather than 1-dimensinal arrays (vectors). Most scikit-learn estimators, including linear regression expect:\n",
    "\n",
    "- `X` to be 2D with shape `(num_samples, num_features)`\n",
    "- `y` can be either 1D or 2D, but it is often safer to keep y in the same format as `X`\n",
    "\n",
    "The double-bracket notation should be interpreted as follows. The outer pair of brackets denote the standard column selection operation in pandas. The inner pair define a list of column lables. When a list of column labels is provided, pandas will always generate a 2D array of size `n x p`.\n",
    "\n",
    "For example, if you wanted `X` to include both GDP and country, specify both columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "lifesat[[\"GDP per capita (USD)\", \"Country\"]].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "But in this case, `p` is 1 and `n` is 27, so both `X` and `y` 1 column and 27 rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "Had the inner pair of brackets been omitted, `X` would be a 1D array, which is not suitable for scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "lifesat[\"GDP per capita (USD)\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "Let's visualize the relationship between `X` and `y` with a scatter chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data\n",
    "lifesat.plot(kind='scatter', grid=True,\n",
    "             x=\"GDP per capita (USD)\", y=\"Life satisfaction\")\n",
    "# specify ranges for both axes, recall that the underbar character is ignored\n",
    "plt.axis([23_500, 62_500, 4, 9])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "Based on the general shape of the data, this appears to be a good candidate for SLR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "### Initialize the Model\n",
    "\n",
    "Fit the data using the scikit-learn's `LinearRegression` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and instantiate the linear model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "To get more information on the model, use Python's `help()` system. When using a Jupyter Notebook, the alternative `?` syntax provides a more readable format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "LinearRegression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "### Fit the Training Data\n",
    "\n",
    "Let's train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_, model.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "### Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "Let's start by visualizing the line of best fit by combining the scatter plot with a line of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X, y)\n",
    "plt.plot(X, model.predict(X), color='red')\n",
    "plt.xlabel(\"GDP per capita (USD)\")\n",
    "plt.ylabel(\"Life satisfaction\")\n",
    "plt.axis([23_500, 62_500, 4, 9])\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "Next let's calculate some common measures of model fit, starting with $R^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score = model.score(X, y)\n",
    "print(f\"R-squared: {r2_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "This result suggests that approximately 72.7% of the variance in life satisfaction ($y$) can be explained by differences in GDP per capita ($X$). The remaining 27.3% of variance can be attributed to:\n",
    "\n",
    "- Reducible error\n",
    "  - model form: linear may be too simple (bias)\n",
    "  - predictors: may be missing factors important to life satisfaction\n",
    "- Irreducible error\n",
    "  - random effects: random fluctuations and inherent variablity in life satisfaction\n",
    "  - measurement error: how do you measure the outcome consistently, accurately?\n",
    "  - unidentified or unmeasureable factors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "Now let's look at three other measures, all based on residuals:\n",
    "\n",
    "- Residual Standard Error (RSE), also known as the standard error of the regression: $$RSE = \\sqrt{\\frac{1}{n-2}RSS} \\text{, where } RSS = \\sum(y_i - \\hat{y}_i)^2$$\n",
    "- Mean Squared Error (MSE), the average of squared residuals: $$MSE = \\frac{1}{n}\\sum(y_i - \\hat{y}_i)^2$$\n",
    "- Root Mean Squared Error (RMSE), which is simply the square root of MSE: $$RMSE = \\sqrt{MSE}$$\n",
    "\n",
    "We covered RSE in the previous lecture as it is recommended by the primary text (ISL). It is like RMSE, but divides by $n-2$ instead of $n$ to account for estimating two parameters. This is more commonly used in the context of statistical inference, but there is no direct way to calculate it in scikit-learn.\n",
    "\n",
    "It is easy enough (and instructive!) to calculate directly, thanks to numpy / pandas vectorized math:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtract the predictions from the known values to get the residuals\n",
    "residuals = y - model.predict(X)\n",
    "\n",
    "# take the sum of the residuals squared\n",
    "rss = (residuals ** 2).sum()\n",
    "\n",
    "# number of observations is just the length of y or x\n",
    "n = len(y)\n",
    "\n",
    "# calculate rse\n",
    "rse = np.sqrt(rss / (n - 2))\n",
    "\n",
    "print(f\"RSE: {rse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "RMSE is more commonly used in ML and predictive modeling. It is in the same scale of the response variable, making it easier to interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y, model.predict(X))\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "Note that:\n",
    "\n",
    "$$MSE = \\frac{1}{n}RSS \\rightarrow RSS = n(MSE) \\text{, and}$$\n",
    "$$RSE = \\sqrt{\\frac{1}{n-2}RSS} \\rightarrow RSE = \\sqrt{\\frac{n}{n-2}MSE}$$\n",
    "\n",
    "This allows us to use MSE to calculate RSE directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "rse = np.sqrt((n * mse) / (n - 2))\n",
    "print(f\"RSE (from MSE): {rse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "RSE is slightly larger than RMSE, owing to the smaller divisor (`n-2` vs `n`). This adjustment makes RSE a more conservative (larger) estimate of model error.\n",
    "\n",
    "We can also generate a residual plot, Q-Q plot, and histogram of residuals, though it is not essential to check the model assumptions for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create three subplots in a row\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Residual plot\n",
    "ax1.scatter(model.predict(X), residuals)\n",
    "ax1.axhline(y=0, color='r', linestyle='--')\n",
    "ax1.set_xlabel(\"Predicted values\")\n",
    "ax1.set_ylabel(\"Residuals\")\n",
    "ax1.set_title(\"Residual Plot\")\n",
    "ax1.grid(True)\n",
    "\n",
    "# Q-Q plot\n",
    "from scipy import stats\n",
    "stats.probplot(residuals.ravel(), plot=ax2)\n",
    "ax2.set_title(\"Q-Q Plot\")\n",
    "\n",
    "# Histogram of residuals\n",
    "ax3.hist(residuals, bins=6, edgecolor='black')\n",
    "ax3.set_xlabel(\"Residuals\")\n",
    "ax3.set_ylabel(\"Frequency\")\n",
    "ax3.set_title(\"Histogram of Residuals\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "Brief interpretation:\n",
    "1. Residual Plot: No obvious pattern, though slight fan shape might indicate minor heteroscedasticity (increasing variance with higher predicted values)\n",
    "2. Q-Q Plot: Points follow diagonal line reasonably well, suggesting residuals are approximately normally distributed\n",
    "3. Histogram: Roughly bell-shaped but with small sample size, hard to make strong claims about normality\n",
    "\n",
    "For prediction purposes, these diagnostics suggest the model is adequate. The violations of assumptions aren't severe enough to invalidate predictions, though they might be more concerning if we were doing inferential analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "### Make Predictions\n",
    "\n",
    "Finally, let's make a prediciton for Cyprus, which had a per capita GDP of $37,655.20 in 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction\n",
    "X_new = [[37_655.2]]  # Cyprus' GDP per capita in 2020\n",
    "model.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "Confirm that Cyprus was not in the original dataset using a membership test (`in`) on the values of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Cyprus\" in lifesat[\"Country\"].values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
