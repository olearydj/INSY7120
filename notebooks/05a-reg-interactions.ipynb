{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Regression: Interactions & Polynomials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "Load the packages and configure environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Interaction Terms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### Advertising Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "Using the Advertising data from ISL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the data set directly from the web using pandas\n",
    "url = \"https://raw.githubusercontent.com/olearydj/INSY7120/refs/heads/main/notebooks/data/Advertising.csv\"\n",
    "data = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall that we need to drop the duplicated row numbers in the first column\n",
    "sales = data.drop(data.columns[0], axis=1)\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "If we are interested in a model based on radio, TV and their interaction, first get the **main effects**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the predictors of interest\n",
    "X = sales[['radio', 'TV']]\n",
    "y = sales[['sales']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "Then use `PolynomialFeatures` from SKL to transform the features before fitting the model. In this case:\n",
    "\n",
    "- `degree=2` limited to two-way interactions (products of two variables) between features\n",
    "- `interaction_only=True` generates only the interaction terms (e.g., $radio \\times tv$), without the squared terms (e.g., $radio^2$)\n",
    "- `include_bias=False` lets LinearRegression compute the intercept\n",
    "\n",
    "The process below first specifies the transformation and then applies it with the fit method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate interaction terms\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "X_interact = poly.fit_transform(X)\n",
    "\n",
    "# inspect result - no head method for numpy, slice\n",
    "X_interact[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "We can see that the first two columns are the original values for radio and TV and the third is their product.\n",
    "\n",
    "To confirm the features created, use `poly.get_feature_names_out()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "After transforming the input features, we can continue fitting the model and evaluating the results, as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlr_interact = LinearRegression()\n",
    "\n",
    "# use the transformed predictors!\n",
    "mlr_interact.fit(X_interact, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the estimated model parameters\n",
    "print(f\"Model Coefficients: {mlr_interact.coef_}\")\n",
    "print(f\"Model Intercept: {mlr_interact.intercept_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions with interaction data!\n",
    "y_pred = mlr_interact.predict(X_interact)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y, y_pred)\n",
    "\n",
    "print(f\"Multiple Linear Regression Model, with Interaction Terms:\")\n",
    "print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"R² Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "Compare without interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlr = LinearRegression()\n",
    "mlr.fit(X, y)\n",
    "\n",
    "# for just r2, use score method of fitted model\n",
    "# this generates predictions implicitly\n",
    "# for other metrics you need to predict first\n",
    "r2 = mlr.score(X, y)\n",
    "print(f\"R² Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "Define a function to simplify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_fit(X, y):\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    r2 = model.score(X,y)\n",
    "    print(f\"R² Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "Compare with SLR using radio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sales[['radio']]\n",
    "quick_fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "Compare with SLR using TV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sales[['TV']]\n",
    "quick_fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "SLR radio (0.332) < SLR TV (0.612) < MLR radio + TV (0.897) < MLR radio * TV (0.968)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "### Credit Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "Use `Credit` dataset from ISL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the data set directly from the web using pandas\n",
    "url = \"https://raw.githubusercontent.com/olearydj/INSY7120/refs/heads/main/notebooks/data/Credit.csv\"\n",
    "credit = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "credit.columns = credit.columns.str.lower()\n",
    "credit = pd.get_dummies(credit, drop_first=True, dtype=int)\n",
    "credit.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "Predict `balance` from `income` (quant) and `student` (qual)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the predictors of interest\n",
    "X = credit[['income', 'student_Yes']]\n",
    "y = credit[['balance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "X_interact = poly.fit_transform(X)\n",
    "\n",
    "# inspect result - no head method for numpy, slice\n",
    "X_interact[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_fit(X_interact, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with two subplots side by side\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
    "fig.suptitle('Income vs Balance by Student Status: Without vs With Interaction', fontsize=16)\n",
    "\n",
    "# Get student and non-student data\n",
    "students = credit[credit['student_Yes'] == 1]\n",
    "non_students = credit[credit['student_Yes'] == 0]\n",
    "\n",
    "# Common x range for prediction lines\n",
    "x_range = np.linspace(credit['income'].min(), credit['income'].max(), 100)\n",
    "\n",
    "# ------ Left plot: Model without interaction (X) ------\n",
    "# Scatter all data points\n",
    "axes[0].scatter(non_students['income'], non_students['balance'], alpha=0.5, color='blue', label='Non-Student')\n",
    "axes[0].scatter(students['income'], students['balance'], alpha=0.5, color='red', label='Student')\n",
    "\n",
    "# Fit model without interaction\n",
    "model_no_interact = LinearRegression().fit(X, y)\n",
    "\n",
    "# Predict for non-students and students - use DataFrames to match training data\n",
    "X_pred_non = pd.DataFrame({'income': x_range, 'student_Yes': np.zeros(100)})\n",
    "X_pred_stu = pd.DataFrame({'income': x_range, 'student_Yes': np.ones(100)})\n",
    "y_pred_non = model_no_interact.predict(X_pred_non)\n",
    "y_pred_stu = model_no_interact.predict(X_pred_stu)\n",
    "\n",
    "# Plot regression lines\n",
    "axes[0].plot(x_range, y_pred_non, 'b-', linewidth=2, label='Non-Student Line')\n",
    "axes[0].plot(x_range, y_pred_stu, 'r-', linewidth=2, label='Student Line')\n",
    "axes[0].set_title('Without Interaction (Main Effects Only)')\n",
    "axes[0].set_xlabel('Income')\n",
    "axes[0].set_ylabel('Balance')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# ------ Right plot: Model with interaction (X_interact) ------\n",
    "# Scatter all data points\n",
    "axes[1].scatter(non_students['income'], non_students['balance'], alpha=0.5, color='blue', label='Non-Student')\n",
    "axes[1].scatter(students['income'], students['balance'], alpha=0.5, color='red', label='Student')\n",
    "\n",
    "# Fit model with interaction\n",
    "model_interact = LinearRegression().fit(X_interact, y)\n",
    "\n",
    "# Prepare prediction data for interaction model\n",
    "X_interact_pred_non = poly.transform(X_pred_non)  # Transform with interaction for non-students\n",
    "X_interact_pred_stu = poly.transform(X_pred_stu)  # Transform with interaction for students\n",
    "y_interact_pred_non = model_interact.predict(X_interact_pred_non)\n",
    "y_interact_pred_stu = model_interact.predict(X_interact_pred_stu)\n",
    "\n",
    "# Plot regression lines\n",
    "axes[1].plot(x_range, y_interact_pred_non, 'b-', linewidth=2, label='Non-Student Line')\n",
    "axes[1].plot(x_range, y_interact_pred_stu, 'r-', linewidth=2, label='Student Line') \n",
    "axes[1].set_title('With Interaction')\n",
    "axes[1].set_xlabel('Income')\n",
    "axes[1].set_ylabel('Balance')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "**Left (Without Interaction):** The lines are *parallel*. The model says students carry ~\\$200 more balance than non-students at any income level, but the *rate* at which balance increases with income is identical for both groups. This is the \"main effects only\" model:\n",
    "\n",
    "$$\\text{balance} = \\beta_0 + \\beta_1 \\cdot \\text{income} + \\beta_2 \\cdot \\text{student}$$\n",
    "\n",
    "**Right (With Interaction):** The lines have *different slopes*. For non-students, balance increases more steeply with income. For students, the slope is flatter - their balance increases more slowly as income rises. The interaction term captures this:\n",
    "\n",
    "$$\\text{balance} = \\beta_0 + \\beta_1 \\cdot \\text{income} + \\beta_2 \\cdot \\text{student} + \\beta_3 \\cdot (\\text{income} \\times \\text{student})$$\n",
    "\n",
    "Without the interaction, the model *forces* the relationship between income and balance to be the same for both groups. The interaction term *allows* that relationship to differ - which better matches the data pattern where high-income students don't accumulate balance as quickly as high-income non-students."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "## Polynomial Terms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "Use `Auto` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the data set directly from the web using pandas\n",
    "url = \"https://raw.githubusercontent.com/olearydj/INSY7120/refs/heads/main/notebooks/data/Auto.csv\"\n",
    "cars = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "`autos` includes question marks for some horsepower values (5 rows). For this example we'll simply convert them to `NaN` and drop those rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars['horsepower'] = pd.to_numeric(cars['horsepower'], errors='coerce')\n",
    "cars_clean = cars.dropna(subset=['horsepower'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "Same procedure as before, except `interaction_only=False` (the default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the predictors of interest\n",
    "X = cars_clean[['horsepower']]\n",
    "y = cars_clean[['mpg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate polynomial terms\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=False, include_bias=False)\n",
    "X_interact = poly.fit_transform(X)\n",
    "\n",
    "# inspect result - no head method for numpy, slice\n",
    "X_interact[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_power = LinearRegression()\n",
    "cars_power.fit(X_interact, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the estimated model parameters\n",
    "print(f\"Model Coefficients: {cars_power.coef_}\")\n",
    "print(f\"Model Intercept: {cars_power.intercept_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions with interaction data!\n",
    "y_pred = cars_power.predict(X_interact)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y, y_pred)\n",
    "\n",
    "print(f\"Multiple Linear Regression Model, with Polynomial Terms:\")\n",
    "print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"R² Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "## Many Terms: The Curse of Dimensionality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "What happens when we use multiple predictors with polynomial and interaction terms? The number of features can explode quickly.\n",
    "\n",
    "Let's use all quantitative predictors from the Auto dataset. First, inspect the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_clean.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "Use `loc` to select a range of columns by name. Here we grab all numeric predictors from `cylinders` through `year`, excluding `mpg` (our target) and `name`/`origin` (non-numeric)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select quantitative predictors using loc with column range\n",
    "X_multi = cars_clean.loc[:, 'cylinders':'year']\n",
    "y = cars_clean[['mpg']]\n",
    "\n",
    "print(f\"Original predictors: {X_multi.shape[1]}\")\n",
    "X_multi.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58",
   "metadata": {},
   "source": [
    "**Alternative selection methods:** There are several ways to select columns in pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: loc with column range (used above)\n",
    "X1 = cars_clean.loc[:, 'cylinders':'year']\n",
    "\n",
    "# Method 2: select_dtypes - all numeric columns, then drop target\n",
    "X2 = cars_clean.select_dtypes(include='number').drop(columns=['mpg'])\n",
    "\n",
    "# Method 3: iloc with positional indices (columns 1-6)\n",
    "X3 = cars_clean.iloc[:, 1:7]\n",
    "\n",
    "# Method 4: explicit column list\n",
    "cols = ['cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'year']\n",
    "X4 = cars_clean[cols]\n",
    "\n",
    "# Verify all methods give same result\n",
    "print(f\"All methods equivalent: {X1.equals(X2) and X2.equals(X3) and X3.equals(X4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60",
   "metadata": {},
   "source": [
    "Now apply `PolynomialFeatures` with degree=3 and `interaction_only=False` to generate all polynomial and interaction terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_full = PolynomialFeatures(degree=3, interaction_only=False, include_bias=False)\n",
    "X_poly = poly_full.fit_transform(X_multi)\n",
    "\n",
    "print(f\"Original features: {X_multi.shape[1]}\")\n",
    "print(f\"After degree=3 polynomial expansion: {X_poly.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "From 6 predictors to 83 features! This includes:\n",
    "- 6 original terms (degree 1)\n",
    "- 21 degree-2 terms (6 squared + 15 two-way interactions)\n",
    "- 56 degree-3 terms (6 cubed + various combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View a sample of the generated feature names\n",
    "feature_names = poly_full.get_feature_names_out()\n",
    "print(f\"First 10: {list(feature_names[:10])}\")\n",
    "print(f\"Last 10: {list(feature_names[-10:])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and evaluate\n",
    "model_poly = LinearRegression()\n",
    "model_poly.fit(X_poly, y)\n",
    "\n",
    "r2_poly = r2_score(y, model_poly.predict(X_poly))\n",
    "print(f\"R² with 83 features: {r2_poly:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65",
   "metadata": {},
   "source": [
    "The R² is very high, but with 83 features and only 392 observations, we're at serious risk of overfitting. The model may be fitting noise rather than signal. This is the **curse of dimensionality** - more features require exponentially more data to estimate reliably.\n",
    "\n",
    "In practice, we'd use techniques like cross-validation (next lecture) and regularization to manage this complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66",
   "metadata": {},
   "source": [
    "## PolynomialFeatures Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67",
   "metadata": {},
   "source": [
    "### Terms Generated by Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "Given 2 predictors (X₁, X₂), `include_bias=False` (see note in the section that follows):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69",
   "metadata": {},
   "source": [
    "#### SLR (1 predictor: X₁)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70",
   "metadata": {},
   "source": [
    "| degree | Terms |\n",
    "|--------|-------|\n",
    "| 1 | X₁ |\n",
    "| 2 | X₁, X₁² |\n",
    "| 3 | X₁, X₁², X₁³ |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71",
   "metadata": {},
   "source": [
    "#### MLR (2 predictors: X₁, X₂) — no PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72",
   "metadata": {},
   "source": [
    "| degree | Terms |\n",
    "|--------|-------|\n",
    "| 1 | X₁, X₂ |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73",
   "metadata": {},
   "source": [
    "#### PolynomialFeatures with `interaction_only=True`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74",
   "metadata": {},
   "source": [
    "| degree | Terms | Notes |\n",
    "|--------|-------|-------|\n",
    "| 1 | X₁, X₂ | main effects only |\n",
    "| 2 | X₁, X₂, X₁X₂ | adds cross-term |\n",
    "| 3 | X₁, X₂, X₁X₂ | same as degree=2* |\n",
    "\n",
    "*With only 2 features, degree=3 adds nothing new for `interaction_only=True` since a 3-way interaction requires 3 distinct features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75",
   "metadata": {},
   "source": [
    "#### PolynomialFeatures with `interaction_only=False` (default)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76",
   "metadata": {},
   "source": [
    "| degree | Terms |\n",
    "|--------|-------|\n",
    "| 1 | X₁, X₂ |\n",
    "| 2 | X₁, X₂, X₁², X₂², X₁X₂ |\n",
    "| 3 | X₁, X₂, X₁², X₂², X₁X₂, X₁³, X₂³, X₁²X₂, X₁X₂² |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77",
   "metadata": {},
   "source": [
    "#### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78",
   "metadata": {},
   "source": [
    "What each setting excludes/includes\n",
    "\n",
    "| Setting | Squared terms (X₁²) | Cross-terms (X₁X₂) | Higher powers (X₁³) | Mixed powers (X₁²X₂) |\n",
    "|---------|---------------------|--------------------|--------------------|----------------------|\n",
    "| `interaction_only=True` | ❌ | ✅ | ❌ | ❌ |\n",
    "| `interaction_only=False` | ✅ | ✅ | ✅ | ✅ |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79",
   "metadata": {},
   "source": [
    "### The `include_bias` Parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80",
   "metadata": {},
   "source": [
    "`include_bias` adds a column of 1s (the constant term, β₀) to the feature matrix.\n",
    "\n",
    "| `include_bias` | Terms for degree=2, interaction_only=False |\n",
    "|----------------|-------------------------------------------|\n",
    "| `False` | X₁, X₂, X₁², X₂², X₁X₂ |\n",
    "| `True` | **1**, X₁, X₂, X₁², X₂², X₁X₂ |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81",
   "metadata": {},
   "source": [
    "#### Why it matters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82",
   "metadata": {},
   "source": [
    "| Scenario | `include_bias` | Why |\n",
    "|----------|----------------|-----|\n",
    "| Using with `LinearRegression()` | `False` | LR adds its own intercept via `fit_intercept=True` (default) |\n",
    "| Manual matrix math (X'X)⁻¹X'y | `True` | You need the 1s column to estimate β₀ |\n",
    "| Using a model with no intercept | `True` | Must provide the constant term yourself |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83",
   "metadata": {},
   "source": [
    "#### The danger of getting it wrong"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84",
   "metadata": {},
   "source": [
    "```python\n",
    "# BAD: redundant intercept → multicollinearity\n",
    "poly = PolynomialFeatures(degree=2, include_bias=True)  # adds 1s column\n",
    "model = LinearRegression(fit_intercept=True)             # adds another intercept\n",
    "\n",
    "# GOOD: let LinearRegression handle it\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "model = LinearRegression()  # fit_intercept=True by default\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85",
   "metadata": {},
   "source": [
    "#### Bottom line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86",
   "metadata": {},
   "source": [
    "For typical sklearn workflows, always use `include_bias=False` and let the regression model handle the intercept."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "default_lexer": "ipython3"
  },
  "kernelspec": {
   "display_name": "insy7120-py4sml",
   "language": "python",
   "name": "insy7120-py4sml"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
