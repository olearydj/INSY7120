{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Python Quick Start for Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "This notebook provides a minimal foundation in Python, NumPy, and Pandas for students following along with INSY 7120. It is not a comprehensive introduction to Python programming - for that, see INSY 5/6500.\n",
    "\n",
    "The goal is to give you just enough context to understand what's happening in our scikit-learn notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Python Essentials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "Everything in Python has a type and a value. These things are called *objects*. The core object types in Python are:\n",
    "\n",
    "| Type | What it holds | Example |\n",
    "|------|---------------|---------|\n",
    "| `int` | Whole numbers | `42` |\n",
    "| `float` | Decimal numbers | `3.14` |\n",
    "| `str` | Text (sequence of characters) | `\"hello\"` |\n",
    "| `list` | Ordered, mutable sequence | `[1, 2, 3]` |\n",
    "| `tuple` | Ordered, immutable sequence | `(1, 2, 3)` |\n",
    "| `set` | Unordered collection of unique values | `{1, 2, 3}` |\n",
    "| `dict` | Key-value mappings | `{\"a\": 1, \"b\": 2}` |\n",
    "| `bool` | Logical values | `True`, `False` |\n",
    "| `None` | Absence of value | `None` |\n",
    "\n",
    "*Mutable* objects can be changed after creation (e.g., append to a list). *Immutable* objects cannot - any \"change\" creates a new object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### Program Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "Python code is organized in a hierarchy:\n",
    "\n",
    "| Level | Description |\n",
    "|-------|-------------|\n",
    "| Modules / Packages | Reusable blocks of functionality, composed of... |\n",
    "| Scripts / Notebooks | Programs that accomplish a task, composed of... |\n",
    "| Functions | Single-purpose tools (verbs), composed of... |\n",
    "| Statements | Instructions that change internal or external state, composed of... |\n",
    "| Expressions | Any combination of values, variables, operators, and function calls that evaluates to an object |\n",
    "\n",
    "For example, `x * 2 + 1` is an expression. `y = x * 2 + 1` is a statement (it assigns the result to `y`). A function groups statements into a reusable tool. A script or notebook combines functions and statements to accomplish something. A module packages code for others to import."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "Python includes many other object types beyond those listed above, but these are the primary building blocks. The formal term for type is *class* (i.e., a class of object). If functions are Python's verbs, classes are its nouns.\n",
    "\n",
    "Classes bundle variables and functions relevant to objects of that type, accessed using *dot notation*. The variables are called *attributes* and hold data (like `arr.shape`). The functions are called *methods* (like `df.head()`).\n",
    "\n",
    "The entire Python ecosystem - including NumPy, Pandas, and scikit-learn - is built on this foundation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Why NumPy?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "Python is a general-purpose language. It's great for many tasks, but numerical computation with native Python data structures (like lists) is slow.\n",
    "\n",
    "To use NumPy, we first import it. By convention, it's aliased as `np`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "Consider a simple task: double every value in a collection of 1 million numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list with 1 million elements\n",
    "my_list = list(range(1_000_000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "Using a list comprehension (Python's concise loop syntax):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit my_list2 = [x * 2 for x in my_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "List comprehension is just shorthand for the following loop:\n",
    "\n",
    "```python\n",
    "my_list2 = []\n",
    "for x in my_list:\n",
    "    my_list2.append(x * 2)\n",
    "```\n",
    "\n",
    "Both approaches iterate through each element one at a time - that's why they're slow.\n",
    "\n",
    "Now compare with NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_array = np.array(my_list)  # convert Python list into NumPy array\n",
    "%timeit my_array2 = my_array * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "Typical results: 12.3 *milliseconds* (python list) vs 469 *microseconds* (numpy array) - about 26x faster (1 ms = 1000 μs, so 12,300 / 469 = 26.2x)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "NumPy is typically 20-100x faster for numerical operations. Why?\n",
    "\n",
    "1. Homogeneous types: Every element in a NumPy array has the same data type, so the computer knows exactly how much memory each element needs\n",
    "2. Contiguous memory: Elements are stored next to each other in memory, making access predictable and fast\n",
    "3. Vectorized operations: Operations happen in optimized C code, not Python loops\n",
    "\n",
    "The key insight: Think in terms of array operations, not element-by-element loops."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## NumPy Essentials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### Creating Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "Use `np.array()` to convert Python lists into NumPy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D array from a list (like a table row)\n",
    "row = [1, 2, 3, 4, 5]\n",
    "arr_1d = np.array(row)\n",
    "print(arr_1d)\n",
    "print(type(arr_1d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D array from a nested list (like a table)\n",
    "table = [\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9]\n",
    "]\n",
    "arr_2d = np.array(table)\n",
    "print(arr_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "Notice that NumPy arrays display without commas between elements - this helps visually distinguish them from Python lists."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "### Shape and Dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "Every array has a shape (the size of each axis) and a data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"1D array:\")\n",
    "print(\"  shape:\", arr_1d.shape)   # (5,) - one axis with 5 elements\n",
    "print(\"  ndim:\", arr_1d.ndim)     # 1 dimension\n",
    "print(\"  dtype:\", arr_1d.dtype)   # int64\n",
    "\n",
    "print(\"\\n2D array:\")\n",
    "print(\"  shape:\", arr_2d.shape)   # (3, 3) - 3 rows, 3 columns\n",
    "print(\"  ndim:\", arr_2d.ndim)     # 2 dimensions\n",
    "print(\"  dtype:\", arr_2d.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "Understanding shape is critical for scikit-learn. The shape tells you:\n",
    "- How many samples (rows) you have\n",
    "- How many features (columns) you have"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "### Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "NumPy arrays are *homogeneous* - all elements must be the same type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_arr = np.array([1, 2, 3])\n",
    "float_arr = np.array([1., 2., 3.])\n",
    "text_arr = np.array(['a', 'b', 'c'])\n",
    "\n",
    "print(\"Integer array:\", int_arr.dtype)   # int64\n",
    "print(\"Float array:\", float_arr.dtype)   # float64\n",
    "print(\"Text array:\", text_arr.dtype)     # Unicode string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "Mixed types get converted automatically (sometimes in surprising ways).\n",
    "\n",
    "Mixing integers and floats upcasts to float:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed = np.array([1, 2, 3.5])\n",
    "print(\"Mixed int/float:\", mixed.dtype, mixed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "Mixing numbers and text converts everything to text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_text = np.array([1, 2, 'text'])\n",
    "print(\"Mixed with text:\", mixed_text.dtype, mixed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "### Indexing and Slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "For 1D arrays, indexing works just like Python lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First element:\", arr_1d[0])\n",
    "print(\"Last element:\", arr_1d[-1])\n",
    "print(\"First three:\", arr_1d[0:3])\n",
    "print(\"Every other:\", arr_1d[::2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "For 2D arrays, NumPy uses `[row, col]` syntax - both indices in a single set of brackets, separated by a comma. This is different from base Python, where you'd chain brackets: `list[row][col]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(arr_2d)\n",
    "print(\"Element at row 1, col 1:\", arr_2d[1, 1])\n",
    "print(\"First row:\", arr_2d[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "Each position can also contain a slice using standard Python `start:stop:step` notation. A lone `:` means \"all\" along that axis.\n",
    "\n",
    "So `arr[:, 0]` means \"all rows, column 0\" - an easy way to select a column. In base Python, you'd need a loop to extract a column from a list of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First column:\", arr_2d[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "Slices work in either position:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First two rows:\\n\", arr_2d[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "### Vectorized Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "*Vectorized operations* apply to all elements at once, without explicit loops. This is the key to writing fast NumPy code.\n",
    "\n",
    "Arithmetic on every element:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([1, 2, 3, 4, 5])\n",
    "\n",
    "print(\"Double:\", arr * 2)\n",
    "print(\"Squared:\", arr ** 2)\n",
    "print(\"Add 10:\", arr + 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "In base Python, you'd need a loop for this. For 2D arrays, you'd need nested loops - one for rows, one for columns:\n",
    "\n",
    "```python\n",
    "result = []\n",
    "for row in table:\n",
    "    new_row = []\n",
    "    for val in row:\n",
    "        new_row.append(val * 2)\n",
    "    result.append(new_row)\n",
    "```\n",
    "\n",
    "Aggregations (sum, mean, etc.) also require loops in base Python. NumPy replaces all of this with concise, fast operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "Operations between arrays are element-wise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2 = np.array([10, 20, 30, 40, 50])\n",
    "print(\"Sum:\", arr + arr2)\n",
    "print(\"Product:\", arr * arr2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "Aggregation methods reduce an array to a single value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sum of all:\", arr.sum())\n",
    "print(\"Mean:\", arr.mean())\n",
    "print(\"Max:\", arr.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "### Boolean Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "Comparisons produce arrays of True/False values. These boolean arrays can be used to filter data - only elements where the condition is True are selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([1, 5, 3, 8, 2, 9, 4])\n",
    "\n",
    "print(\"Greater than 4:\", arr > 4)\n",
    "print(\"Values > 4:\", arr[arr > 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "### Quick Reference\n",
    "\n",
    "| Attribute/Method | What it does | Example |\n",
    "|------------------|--------------|---------|\n",
    "| `.shape` | Dimensions as tuple | `(3, 4)` = 3 rows, 4 cols |\n",
    "| `.ndim` | Number of dimensions | `2` |\n",
    "| `.dtype` | Data type of elements | `int64`, `float64` |\n",
    "| `.sum()` | Sum of all elements | |\n",
    "| `.mean()` | Average of elements | |\n",
    "| `.max()`, `.min()` | Extreme values | |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "## Pandas Essentials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58",
   "metadata": {},
   "source": [
    "Pandas is built on NumPy but designed for *tabular data* - the kind of data you'd see in a spreadsheet or database table.\n",
    "\n",
    "To use Pandas, we import it. By convention, it's aliased as `pd`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60",
   "metadata": {},
   "source": [
    "### Observations and Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61",
   "metadata": {},
   "source": [
    "Tabular data has a fundamental structure:\n",
    "- Rows are observations (samples, records, instances) - each row describes one thing\n",
    "- Columns are attributes (features, variables, measurements) - each column describes one property\n",
    "\n",
    "When we look at a table, we naturally read row by row. But analysis is almost always about how attributes vary across observations:\n",
    "- \"What's the average age?\" - summarize the age attribute\n",
    "- \"Find everyone over 30\" - filter observations by an attribute\n",
    "- \"Does income predict spending?\" - relate two attributes across observations\n",
    "\n",
    "This is why Pandas is *column-based*. It stores and operates on data one column at a time, because that's how we analyze it.\n",
    "\n",
    "Each column contains values of the same type (all numbers, all text, all dates), so it can be stored as a fast NumPy array. A DataFrame is essentially a collection of these column-arrays that share a row index.\n",
    "\n",
    "This structure has implications:\n",
    "- Selecting a column is instant: `df[\"age\"]`\n",
    "- Column operations are fast: `df[\"price\"] * df[\"quantity\"]`\n",
    "- Data should be organized so each row is one observation and each column is one attribute (this is called \"tidy\" data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "### The Mental Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63",
   "metadata": {},
   "source": [
    "Think of a Pandas DataFrame as a dictionary of named NumPy arrays that share a common row index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from a dictionary\n",
    "data = {\n",
    "    \"state\": [\"Ohio\", \"Ohio\", \"Nevada\", \"Nevada\"],\n",
    "    \"year\": [2000, 2001, 2001, 2002],\n",
    "    \"pop\": [1.5, 1.7, 2.4, 2.9]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65",
   "metadata": {},
   "source": [
    "Each column is a Series (a 1D labeled array):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(df[\"pop\"]))\n",
    "print(df[\"pop\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "Most often you'll load data from a file (or url or zip - the syntax is the same):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://github.com/ageron/data/raw/main/lifesat/lifesat.csv\"\n",
    "lifesat = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70",
   "metadata": {},
   "source": [
    "### Exploring Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71",
   "metadata": {},
   "source": [
    "A handful of methods tell you what you're working with.\n",
    "\n",
    "First few rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "lifesat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73",
   "metadata": {},
   "source": [
    "Structure - columns, types, non-null counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "lifesat.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75",
   "metadata": {},
   "source": [
    "Summary statistics for numeric columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "lifesat.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77",
   "metadata": {},
   "source": [
    "Shape as (rows, columns):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "lifesat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79",
   "metadata": {},
   "source": [
    "### Selecting Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80",
   "metadata": {},
   "source": [
    "Access columns by name using bracket notation.\n",
    "\n",
    "Single column returns a Series (1D):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {},
   "outputs": [],
   "source": [
    "lifesat[\"Country\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82",
   "metadata": {},
   "source": [
    "Multiple columns returns a DataFrame (2D):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {},
   "outputs": [],
   "source": [
    "lifesat[[\"Country\", \"GDP per capita (USD)\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84",
   "metadata": {},
   "source": [
    "### Selecting Rows and Cells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85",
   "metadata": {},
   "source": [
    "Pandas offers a variety of ways to access parts of a dataframe and best practice has evolved over time. For this course:\n",
    "\n",
    "- Use brackets for column(s) by name.\n",
    "  - `df[\"col\"]` → column by name\n",
    "- Use `.loc[]` or `.iloc[]` for everything else.\n",
    "  - `.loc[row, col]` → by label\n",
    "  - `.iloc[row, col]` → by position (integer index)\n",
    "\n",
    "Select rows by index position:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First row:\")\n",
    "print(lifesat.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87",
   "metadata": {},
   "source": [
    "Select specific cell by label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First country:\", lifesat.loc[0, \"Country\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89",
   "metadata": {},
   "source": [
    "Select a range of rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Rows 0-2:\")\n",
    "print(lifesat.iloc[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91",
   "metadata": {},
   "source": [
    "Two gotchas:\n",
    "\n",
    "1. Slicing with brackets refers to rows, not columns. This is an exception to the \"brackets for columns\" rule.\n",
    "   - `df[\"a\":\"c\"]` → rows by label\n",
    "   - `df[0:3]` → rows by position\n",
    "2. `.loc[]` slices are *inclusive* of the endpoint. `.iloc[]` slices are *exclusive* (like Python lists).\n",
    "   - `df.loc[\"a\":\"c\"]` → includes row \"c\"\n",
    "   - `df.iloc[0:3]` → rows 0, 1, 2 (not 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92",
   "metadata": {},
   "source": [
    "### Filtering Rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93",
   "metadata": {},
   "source": [
    "Use boolean expressions to select rows that meet a condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94",
   "metadata": {},
   "outputs": [],
   "source": [
    "wealthy = lifesat[lifesat[\"GDP per capita (USD)\"] > 50000]\n",
    "print(wealthy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96",
   "metadata": {},
   "source": [
    "Missing data is represented as `NaN` (Not a Number). It propagates through calculations - any operation involving NaN produces NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data with missing values\n",
    "data_with_gaps = pd.DataFrame({\n",
    "    \"A\": [1, 2, np.nan, 4],\n",
    "    \"B\": [10, np.nan, 30, 40]\n",
    "})\n",
    "print(data_with_gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98",
   "metadata": {},
   "source": [
    "Check for missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_with_gaps.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100",
   "metadata": {},
   "source": [
    "NaN propagation - the mean of column A ignores NaN, but a manual sum doesn't:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean of A:\", data_with_gaps[\"A\"].mean())  # Pandas handles NaN\n",
    "print(\"Manual sum:\", 1 + 2 + np.nan + 4)          # NaN propagates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102",
   "metadata": {},
   "source": [
    "This is actually a feature - NaN propagation forces you to deal with missing values explicitly. If you ignore them, your results will be NaN, making the problem obvious. Always check for missing data before analysis and decide how to handle it (drop rows, fill with a value, etc.).\n",
    "\n",
    "You may also encounter `None` (Python's null) or `pd.NA` (Pandas' modern missing value indicator). The advantage of `pd.NA` is that it works with nullable integer and boolean types, whereas `np.nan` is a float and forces type conversion. For most purposes, Pandas handles these consistently - just be aware they exist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103",
   "metadata": {},
   "source": [
    "### Quick Reference\n",
    "\n",
    "| Method | What it does |\n",
    "|--------|--------------|\n",
    "| `pd.read_csv(path)` | Load data from CSV file or URL |\n",
    "| `.head()`, `.tail()` | First/last 5 rows |\n",
    "| `.info()` | Column types and non-null counts |\n",
    "| `.describe()` | Summary statistics |\n",
    "| `.shape` | (rows, columns) tuple |\n",
    "| `.isna()` | Boolean mask of missing values |\n",
    "| `df[\"col\"]` | Select column as Series |\n",
    "| `df[[\"col\"]]` | Select column(s) as DataFrame |\n",
    "| `.loc[row, col]` | Select by label |\n",
    "| `.iloc[row, col]` | Select by position |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104",
   "metadata": {},
   "source": [
    "## The Shape Gotcha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105",
   "metadata": {},
   "source": [
    "This is the most common source of confusion when starting with scikit-learn.\n",
    "\n",
    "scikit-learn expects:\n",
    "- `X` (features) to be 2D with shape `(n_samples, n_features)`\n",
    "- `y` (target) to be 1D with shape `(n_samples,)`\n",
    "\n",
    "Even if you have only one feature, `X` must still be 2D."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106",
   "metadata": {},
   "source": [
    "### The Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107",
   "metadata": {},
   "source": [
    "Single brackets return a Series (1D):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_series = lifesat[\"GDP per capita (USD)\"]\n",
    "print(\"Type:\", type(gdp_series))\n",
    "print(\"Shape:\", gdp_series.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109",
   "metadata": {},
   "source": [
    "Double brackets return a DataFrame (2D):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_df = lifesat[[\"GDP per capita (USD)\"]]\n",
    "print(\"Type:\", type(gdp_df))\n",
    "print(\"Shape:\", gdp_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111",
   "metadata": {},
   "source": [
    "### The Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112",
   "metadata": {},
   "source": [
    "When preparing data for scikit-learn, use double brackets and `.values` to get the underlying NumPy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = lifesat[[\"GDP per capita (USD)\"]].values\n",
    "y = lifesat[\"Life satisfaction\"].values\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114",
   "metadata": {},
   "source": [
    "### Why Double Brackets?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115",
   "metadata": {},
   "source": [
    "The bracket notation in Pandas works like this:\n",
    "\n",
    "- `df[\"col\"]` - returns the column named \"col\" as a Series\n",
    "- `df[[\"col\"]]` - returns a DataFrame containing the columns in the list\n",
    "\n",
    "The inner brackets create a list of column names. When you pass a list to `df[...]`, Pandas always returns a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(lifesat[\"Country\"]))\n",
    "print(type(lifesat[[\"Country\"]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117",
   "metadata": {},
   "source": [
    "This is also how you select multiple columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118",
   "metadata": {},
   "outputs": [],
   "source": [
    "lifesat[[\"Country\", \"GDP per capita (USD)\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119",
   "metadata": {},
   "source": [
    "### Quick Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120",
   "metadata": {},
   "source": [
    "| What you write | What you get | Shape |\n",
    "|----------------|--------------|-------|\n",
    "| `df[\"col\"]` | Series | `(n,)` |\n",
    "| `df[[\"col\"]]` | DataFrame | `(n, 1)` |\n",
    "| `df[\"col\"].values` | 1D NumPy array | `(n,)` |\n",
    "| `df[[\"col\"]].values` | 2D NumPy array | `(n, 1)` |\n",
    "\n",
    "For scikit-learn: use double brackets for X, single brackets (or none) for y."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122",
   "metadata": {},
   "source": [
    "Why NumPy?\n",
    "- Python loops are slow; NumPy operations are fast\n",
    "- Think in terms of array operations, not element-by-element loops\n",
    "\n",
    "NumPy essentials:\n",
    "- `.shape` tells you the dimensions: `(rows, cols)`\n",
    "- `.dtype` tells you the data type\n",
    "- Use `[row, col]` for 2D indexing, `[:, col]` for columns\n",
    "- Operations are vectorized - no loops needed\n",
    "\n",
    "Pandas essentials:\n",
    "- DataFrame = dictionary of named Series (columns) with shared row index\n",
    "- `pd.read_csv()` to load data\n",
    "- `.head()`, `.info()`, `.describe()` to explore\n",
    "- `df[\"col\"]` for Series, `df[[\"col\"]]` for DataFrame\n",
    "- `.loc[]` for labels, `.iloc[]` for positions\n",
    "\n",
    "The shape gotcha:\n",
    "- scikit-learn needs X to be 2D: `(n_samples, n_features)`\n",
    "- Use `df[[\"col\"]].values` not `df[\"col\"].values` for X\n",
    "- Use `.shape` to verify your data dimensions\n",
    "\n",
    "Now revisit the previous notebook. You followed the logic well enough the first time through - now you can connect the dots on implementation details like data extraction, array shapes, and method calls."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "default_lexer": "ipython3"
  },
  "kernelspec": {
   "display_name": "insy7120-py4sml",
   "language": "python",
   "name": "insy7120-py4sml"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
