{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Crash Course in Pandas\n",
    "\n",
    "Pandas is built on top of NumPy and adopts many of its idioms. But Pandas is designed for working with heterogenous tabular data, where NumPy is built for n-dimensional homogeneous numerical arrays.\n",
    "\n",
    "Note: Parts of this notebook is adapted from chapter 5 of McKinney, which is available in HTML format here: [Pandas Basics](https://wesmckinney.com/book/pandas-basics).\n",
    "\n",
    "Other portions draw from VanderPlas, chapters 13-16.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Core Data Structures\n",
    "\n",
    "Our work with Pandas will rely on an understanding of its primary data structures, the `pd.Series` and `pd.DataFrame`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Pandas Series\n",
    "\n",
    "`Series` wraps a one-dimensional NumPy array with additional functionality, including named indicies. By default, numbered indicies are assigned.\n",
    "\n",
    "For example, imagine some results from a focus test conducted at various sites around the country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.Series([11.8, 30., 4.2, 3.4])\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "This output shows the default numeric indicies, corresponding values, and data type for the object.\n",
    "\n",
    "The values and index can be accessed through attributes of the same name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(res.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "The values are a standard `ndarray`, but the index is a special type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "The index can consist of any value type. To specify the labels, use the index parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_1 = pd.Series([11.8, 30., 4.2, 3.4],\n",
    "                 index=[\"Orlando\", \"Auburn\", \"Atlanta\", \"Birmingham\"])\n",
    "res_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "This creates an association between the site and its results data. In base Python, associations of this type are typically represented by `dict` (dictionary) objects.\n",
    "\n",
    "You can easily convert a Pandas Series into a Python dictionary with the `to_dict` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_1.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "Python dictionaries map keys (e.g. site names) to values (e.g. results). They are represented by a comma separated list of key:value pairs surrounded by curly brackets.\n",
    "\n",
    "Given a dictionary, you can directly create a Series with labeled indicies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"Miami\": 10.2, \"Auburn\": 15.25, \"Birmingham\": 7.1, \"Tuscaloosa\": 1.0}\n",
    "res_2 = pd.Series(data)\n",
    "res_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "Elements of a Series can be accessed by label using the `[]` operator. Index based access in this fashion is ambiguous and discouraged. In fact, future versions of Pandas will not support index based access for `pd.Series` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res_1['Orlando'])  # clear intent\n",
    "print(res_1[0])          # do we mean a label named `0` or index `0`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "Instead, it is better to use `loc` and `iloc` methods, as described below, for most Series and DataFrame access. This makes the interface consistent and explicit."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "### Pandas DataFrame\n",
    "\n",
    "A DataFrame represents tabular data. It contains an ordered, named collection of columns, each of which is a Series. Because of the associative relationship between names and columns, a DataFrame can be thought of as a dictionary of Series with a shared index.\n",
    "\n",
    "As such, it is common to construct a DataFrame from a Python dictionary, where keys are the column names and values are equal-length lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"state\": [\"Ohio\", \"Ohio\", \"Ohio\", \"Nevada\", \"Nevada\", \"Nevada\"],\n",
    "            \"year\": [2000, 2001, 2002, 2001, 2002, 2003],\n",
    "            \"pop\": [1.5, 1.7, 3.6, 2.4, 2.9, 3.2]}\n",
    "frame = pd.DataFrame(data)\n",
    "print(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "Again, the default numerical index is provided. Columns are listed in the order of keyes in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "You can specify the column order with the argument of the same name, which takes a list of names. If a new column name is included, missing values will result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame2 = pd.DataFrame(data, columns=['year', 'state', 'pop', 'debt'])\n",
    "frame2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "`NaN` (Not A Number) is commonly used to represent missing values in Pandas. We'll discuss it further in a later section.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "Columns can be accessed by name or as attributes using dot notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame2['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame2.year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "Note that named access works for any column name where dot notation will only work when the column name is a valid Python variable name that does not conflict with other methods. As a result, name based access is considered best practice.\n",
    "\n",
    "We can extend the comparison of a Series and a Dictionary to include row lables. As a collection of named columns can be represented by a dictionary of names and column data, each column can be thought of as a collection of named rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nested dictionary of col_name:col_data\n",
    "# where col_data is a dict of year:value\n",
    "populations = {\n",
    "    \"Ohio\": {2000: 1.5, 2001: 1.7, 2002: 3.6},\n",
    "    \"Nevada\": {2001: 2.4, 2002: 2.9},\n",
    "    \"Texas\": {2000: 8.4, 2001: 8.8}\n",
    "}\n",
    "\n",
    "frame3 = pd.DataFrame(populations)\n",
    "print(frame3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "## Diagnostics\n",
    "\n",
    "Series and DataFrame objects share a set of attributes / methods that are useful for getting to know your data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "### Structure\n",
    "\n",
    "The `ndim` and `shape` attributes describe the structure of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a dataframe\n",
    "print(frame)\n",
    "print(\"\\nndim:\", frame.ndim)\n",
    "print(\"shape:\", frame.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a series\n",
    "print(res_1)\n",
    "print(\"\\nndim:\", res_1.ndim)\n",
    "print(\"shape:\", res_1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "**Important Note:** a Series is not the same as a one-dimensional DataFrame. A Series is a one-dimensional labeled array. A DataFrame is **always** two-dimensional, even when it contains only one column or row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([1, 2, 3], index=['a', 'b', 'c'])\n",
    "print(df)\n",
    "print(\"\\nndim:\", df.ndim)\n",
    "print(\"shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "### Data Types\n",
    "\n",
    "The `dtypes` method reports the types of data present in both Series and DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframes have one type per column\n",
    "print(frame.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# series is homogenous, all values must share the same type\n",
    "print(res_1.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "### Head and Tail\n",
    "\n",
    "The `head` and `tail` methods can be used to inspect the first / last 5 rows, respectively. Use the `n` parameter to set the number of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the first 5 rows of a DataFrame\n",
    "print(frame.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the last 3 rows of a Series\n",
    "res_1.tail(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "### Info\n",
    "\n",
    "Get general information about the data structure, including object types and null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "## Indexing with `.loc[]` and `.iloc[]`\n",
    "\n",
    "We've a few approaches to accessing the elements of a Series and DataFrame, along with some cautions / recommendations. This can be a sticky topic, so we offer the following recommendations:\n",
    "\n",
    "- When accessing named **columns** of a DataFrame, use the `df['col_name']` approach described above.\n",
    "- In **all other cases**, use `loc` or `iloc` as described below.\n",
    "\n",
    "While `loc` and `iloc` don't offer the most concise notation, that disadvantage is more than offset by the consistency and explicit nature of this approach. It also aligns with best practices and the direction of Pandas development.\n",
    "\n",
    "Note the use of square brackets to suggest the indexing / slicing syntax. `loc` and `iloc` are special *indexer attributes*, not functions, which are called with parentheses, not brackets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(frame3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "### `.loc[]` for Label-Based Access\n",
    "\n",
    "The `loc` method is available for both Series and DataFrames. It provides a consistent way to access labeled rows and/or columns. To use it, you must specify an index or slice for each axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the first column by name as a series\n",
    "# [all rows, column named \"Ohio\"]\n",
    "frame3.loc[:, \"Ohio\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "In this case, it is more concise and explicit to use the `df['col_name']` syntax as recommended above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame3[\"Ohio\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "In **all other cases**, `loc` is recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the first row by name as a series\n",
    "# [row named 2000, all columns]\n",
    "frame3.loc[2000, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract a single element\n",
    "# [row named 2000, column named \"Texas\"]\n",
    "frame3.loc[2000, \"Texas\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "When you select a single element using `.loc[row, col]`, pandas returns a NumPy scalar - in this case `np.float64(8.4)`. This is because pandas stores its numerical data using NumPy's data types under the hood.\n",
    "\n",
    "While this might look different from a regular Python float like 8.4, you can use it the same way in calculations. As seen in the following example, it is equivalent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(frame3.loc[2000, \"Texas\"] / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract a range by name\n",
    "# row named 2001, cols \"Ohio\" thru \"Nevada\" - inclusive; closed interval, i.e., []\n",
    "frame3.loc[2001, \"Ohio\":\"Nevada\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "**Important Note:** unlike slices in base Python (or even when using `iloc` as we will see), slices in `loc` are **inclusive** of the end point. In the previous example the column data for \"Nevada\" was included in the output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58",
   "metadata": {},
   "source": [
    "### `.iloc[]` for Integer Position-Based Access\n",
    "\n",
    "The `iloc` method is also available for both Series and DataFrame objects. It provides a consistent way to access data by the numerical indicies. As with `loc`, you must specify an index or slice for each axis.\n",
    "\n",
    "The following examples are analogous to the label-based ones above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first column\n",
    "# [all rows, column 0]\n",
    "frame3.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first row\n",
    "# [row 0, all columns]\n",
    "frame3.iloc[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single element\n",
    "# [row 0, column 2]\n",
    "frame3.iloc[0, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# range by position\n",
    "# [row 1, columns 0 and 1] - exclusive of endpoint! half-open interval, i.e., [)\n",
    "frame3.iloc[1, 0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63",
   "metadata": {},
   "source": [
    "Note that `iloc` slices follow base Python, where the endpoint is exclusive. The slice above starts at column zero and goes up to, *but does not include*, the second column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64",
   "metadata": {},
   "source": [
    "### One Last Exception\n",
    "\n",
    "While *indexing* refers to columns, *slicing* refers to rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "area = pd.Series({'California': 423967, 'Texas': 695662,\n",
    "                  'Florida': 170312, 'New York': 141297,\n",
    "                  'Pennsylvania': 119280})\n",
    "\n",
    "pop = pd.Series({'California': 39538223, 'Texas': 29145505,\n",
    "                 'Florida': 21538187, 'New York': 20201249,\n",
    "                 'Pennsylvania': 13002700})\n",
    "\n",
    "data = pd.DataFrame({'area':area, 'pop':pop})\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing refers to rows; inclusive for labels\n",
    "print(data['Texas':'New York'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same when slicing by index, exclusive for index\n",
    "print(data[1:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "This is just something you have to memorize, I'm afraid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69",
   "metadata": {},
   "source": [
    "### Indexed Assignment\n",
    "\n",
    "Any of the indexing methods described above (and others available) can be used to modify the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column via index assignment\n",
    "data[\"density\"] = data[\"pop\"] / data[\"area\"]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[\"California\", \"density\"] = 90\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73",
   "metadata": {},
   "source": [
    "## Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74",
   "metadata": {},
   "source": [
    "As we've seen, `NaN` (Not A Number) is the primary way that Pandas (and NumPy, from which it was inherited) represents missing values. You will likely encounter it frequently when dealing with raw data, which is almost always messy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(frame3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76",
   "metadata": {},
   "source": [
    "In this example, both Nevada and Texas have missing data. We can use the `isna` method (or `isnull` which is the older name for the same) to easily identify missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(frame3.isna())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78",
   "metadata": {},
   "source": [
    "The `isna` operation is applied to every value in the DataFrame, resulting in an array of Boolean values. This is called a *Boolean mask* because, like a physical mask, it covers some things (`False`) while leaving others exposed (`True`). Later, we will learn how to use these masks to select only the values we want to operate on.\n",
    "\n",
    "The `notna` method returns the opposite result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(frame3.notna())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80",
   "metadata": {},
   "source": [
    "### Counting Missing Values\n",
    "\n",
    "In Python, `True` and `False` are alternative representations of `1` and `0`, respectively. We can take advantage of this quirk to easily calculate the number of missing values in a Boolean mask using the `sum` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame3.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82",
   "metadata": {},
   "source": [
    "Connecting a sequence of operations in this manner is called *method chaining* and it works any time that the output of one method is a suitable input for the next.\n",
    "\n",
    "In this example we run `isna` on the data, creating an array of Boolean values. That is passed to the `sum` method of `pd.DataFrame`, which returns the number of `True` values, each equivalent to `1`.\n",
    "\n",
    "Within reason, method chaining can help make code more readable by eliminating the need for intermediate variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83",
   "metadata": {},
   "source": [
    "### NaN Propagation\n",
    "\n",
    "It is important to note that the presence of missing values affects computations. Any operation involving `NaN` will produce a `NaN` result, regardless of any other operands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 + np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85",
   "metadata": {},
   "source": [
    "NaN is said to *propagate* through calculations, spreading to all results derived from it. This ensures that missing or invalid data is exposed, and not supressed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86",
   "metadata": {},
   "source": [
    "You may also see missing values represented by `None` and/or `pd.NA`. The latter was introduced as an alternative to `NaN` that works more consistently across all data types. We'll discuss this more as required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87",
   "metadata": {},
   "source": [
    "### Handling Missing Values\n",
    "\n",
    "In order to get useful results, missing values (however represented) must be dealt with. There are basically four alternatives:\n",
    "\n",
    "1. Correct the source of the data\n",
    "2. Drop missing values\n",
    "3. Replace missing values\n",
    "4. Flag them in another way and work around them\n",
    "\n",
    "The approach to use, methods available, which to use, and how to implement them, is a topic for future study."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88",
   "metadata": {},
   "source": [
    "## Operating on Data in Pandas\n",
    "\n",
    "Pandas builds on NumPy's strengths for quick element-wise operations by preserving the context of Series and DataFrame objects.\n",
    "\n",
    "### Unary Operations Preserve Indicies\n",
    "\n",
    "To begin with, any NumPy numerical function will work on a Series or DataFrame. For unary operations - those that modify an existing object - the index order is preserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "ser = pd.Series(rng.integers(0, 10, 4))\n",
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rng.integers(0, 10, (3, 4)),\n",
    "                  columns=['A', 'B', 'C', 'D'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exponential function in numpy\n",
    "np.exp(ser)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92",
   "metadata": {},
   "source": [
    "Note the indices are preserved. The same is true for any NumPy calculation on a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sin(df * np.pi / 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94",
   "metadata": {},
   "source": [
    "### Binary Operations Align Indicies\n",
    "\n",
    "For operations involving two Series or DataFrame objects, Pandas will maintain the alignment of indicies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95",
   "metadata": {},
   "outputs": [],
   "source": [
    "area = pd.Series({'Alaska': 1723337, 'Texas': 695662,\n",
    "                  'California': 423967}, name='area')\n",
    "\n",
    "population = pd.Series({'California': 39538223, 'Texas': 29145505,\n",
    "                        'Florida': 21538187}, name='population')\n",
    "\n",
    "print('viewed side by side:')\n",
    "print(pd.DataFrame({\"area\": area, \"pop\": population}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96",
   "metadata": {},
   "source": [
    "These Series are unaligned - they don't share the same set of row labels. Alaska is not included in the population data and Florida is missing from area.\n",
    "\n",
    "What happens if we divide the two series objects to compute the population density?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(population / area)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98",
   "metadata": {},
   "source": [
    "We get all the rows from both (the **union** of row labels), where the density is `NaN` for any result where either operand was missing.\n",
    "\n",
    "Pandas does the \"dirty work\" of ensuring that `population['Florida']` is divided by `area['Florida']` and not the row with the numerically equivalent index position, `area['California']`. Below is the side by side output above, modified to add an index column for both `area` (i), and `pop` (j).\n",
    "\n",
    "```text\n",
    "            area       i    pop       j\n",
    "Alaska      1723337.0  0         NaN\n",
    "California   423967.0  1  39538223.0  0\n",
    "Florida           NaN     21538187.0  1\n",
    "Texas        695662.0  2  29145505.0  2\n",
    "```\n",
    "\n",
    "What would NumPy do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas stores the ndarray in the values attribute of Series / DataFrame objects\n",
    "a_np = area.values\n",
    "p_np = population.values\n",
    "print(type(a_np), type(p_np))\n",
    "p_np / a_np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100",
   "metadata": {},
   "source": [
    "Only one of these results is correctly calculated - the one for Texas, which is the last element in both `area` and `population`, so is aligned by coincidence.\n",
    "\n",
    "To do this in base Python you would need to explicitly handle looping through each row calculation (which NumPy does implicitly) while ensuring the rows are aligned (which only Pandas does).\n",
    "\n",
    "The benefits of Pandas' automatic row alignment should be pretty obvious from this example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101",
   "metadata": {},
   "source": [
    "Pandas supports a wide range of arithmetic, comparison, and other operations on Series and DataFrames. Each type is briefly introduced below. We will build on these operations as required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102",
   "metadata": {},
   "source": [
    "### Arithmetic Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103",
   "metadata": {},
   "source": [
    "Typical arithmetic operations between scalars, Series, and DataFrames are performed in element-wise fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample sales data\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'product': ['Apple', 'Banana', 'Orange', 'Mango', 'Kiwi'],\n",
    "    'price': [0.99, 0.59, 0.89, 2.99, 1.99],\n",
    "    'quantity': [100, 120, 80, 45, 75],\n",
    "    'height_inches': [2.5, 7.0, 3.0, 4.0, 2.0]\n",
    "})\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Element-wise operations between Series or DataFrames\n",
    "print(\"10% discount:\\n\")\n",
    "print(df['price'] * 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column with total\n",
    "df['total'] = df['price'] * df['quantity']\n",
    "print(\"With totals:\\n\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert measurements\n",
    "df['height_cm'] = df['height_inches'] * 2.54\n",
    "print(\"With heights in cm:\\n\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108",
   "metadata": {},
   "source": [
    "### Comparison Operations\n",
    "\n",
    "Traditional comparison operators (e.g. greater than) are supported, as well as some methods provide an alternative interface to more complex comparisons (aka \"convenience functions\"). Both return an array of Boolean values, which can be used for masking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple comparison\n",
    "print(\"Expensive items (>$1):\\n\")\n",
    "print(df['price'] > 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110",
   "metadata": {},
   "source": [
    "Any combination of comparisons and element-wise Boolean operators (e.g., `&` or `|`) can be used to construct more complex expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Moderate quantity items (50-100 units):\\n\")\n",
    "print((df['quantity'] >= 50) & (df['quantity'] <= 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112",
   "metadata": {},
   "source": [
    "Or use an equivalent method, when available, to make code more concise and readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# between is equivalent to the comparison above\n",
    "print(\"\\nModerate quantity items (50-100 units):\\n\")\n",
    "print(df['quantity'].between(50, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114",
   "metadata": {},
   "source": [
    "### Operations with Methods\n",
    "\n",
    "Finally, `pd.Series` and `pd.DataFrame` objects offer a wide variety of additional methods for working with data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common methods like round\n",
    "print(\"Rounded prices:\\n\")\n",
    "print(df['price'].round(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enforce minimum values\n",
    "print(\"Quantity floored at 50:\\n\")\n",
    "print(df['quantity'].clip(lower=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by price descending\n",
    "print(\"Sorted by price (highest first):\\n\")\n",
    "print(df.sort_values('price', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118",
   "metadata": {},
   "source": [
    "### Pandas Methods Return new Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119",
   "metadata": {},
   "source": [
    "It is important to note that, *by default, **most*** Pandas Series and DataFrame methods return a new object of that type rather than performing in-place modification.\n",
    "\n",
    "To capture the result of a method, you will need to assign it to a new variable, or reassign it to the original if you wish to replace it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this does not modify df\n",
    "df.sort_values('price')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121",
   "metadata": {},
   "source": [
    "Rarther than modifying the original `df`, this creates and *returns* the result. In Jupyter, the last value returned by a cell is echoed as output. Subsequent operations on `df` would be working with the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this does update df with the sorted result\n",
    "df = df.sort_values(\"price\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123",
   "metadata": {},
   "source": [
    "Here, there is no output to the screen because the returned value is reassigned to `df`. This illustrates an important difference between expressions and statements, and the implications in an interactive Python environment like Jupyter.\n",
    "\n",
    "Alternatively, many Pandas methods support the `inplace` argument, which automatically reassigns the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this has the same result as above\n",
    "df.sort_values('price', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125",
   "metadata": {},
   "source": [
    "## Key Things to Remember\n",
    "\n",
    "- Operations preserve index alignment\n",
    "- When to use name-based column access vs `loc` vs `iloc` - be consistent and explicit!\n",
    "- Missing values (NaN) propagate through operations\n",
    "- Most operations are vectorized (no explicit loops needed)\n",
    "- Methods generally return new objects rather than modifying in place\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
